{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved data for aisdk-2021-12-01.csv  | rows count = 114294\n",
      "Processed and saved data for aisdk-2021-12-02.csv  | rows count = 118868\n",
      "Processed and saved data for aisdk-2021-12-03.csv  | rows count = 153660\n",
      "Processed and saved data for aisdk-2021-12-04.csv  | rows count = 164851\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import to_timestamp, col, sin, cos, acos, length, radians, lit, when, first\n",
    "from pyspark.sql.types import DoubleType\n",
    "import os\n",
    "import math\n",
    "\n",
    "spark = SparkSession.builder.appName(\"ShipDataProcessing\").getOrCreate()\n",
    "\n",
    "file_directory = \"C:/Users/User/Desktop/data_folder/raw_data/\"\n",
    "file_names = [f\"aisdk-2021-12-{str(day).zfill(2)}.csv\" for day in range(1, 32)]  # For files from Dec 1 to Dec 31\n",
    "\n",
    "for file_name in file_names:\n",
    "    file_path = os.path.join(file_directory, file_name)\n",
    "    \n",
    "    df = spark.read.csv(file_path, header=True)\n",
    "    \n",
    "    df = df.withColumnRenamed('# Timestamp', 'timestamp')\\\n",
    "           .withColumnRenamed('Latitude', 'lat')\\\n",
    "           .withColumnRenamed('Longitude', 'long')\\\n",
    "           .withColumnRenamed('Navigational status', 'nav_st')\\\n",
    "           .withColumnRenamed('Type of mobile', 'type_of_mobile')\\\n",
    "           .withColumnRenamed('Ship type', 'ship_type')\\\n",
    "           .withColumn('timestamp', to_timestamp(col('timestamp'), 'dd/MM/yyyy HH:mm:ss'))\\\n",
    "           .withColumn('lat', col('lat').cast(DoubleType()))\\\n",
    "           .withColumn('long', col('long').cast(DoubleType()))\\\n",
    "           .withColumn('SOG', col('SOG').cast(DoubleType()))\n",
    "    \n",
    "    df = df.filter(~df['nav_st'].isin(['At anchor', 'Moored', 'Engaged in fishing', 'Unknown value']))\\\n",
    "        .filter(col('SOG').isNotNull())\\\n",
    "        .filter(col('SOG') != 0)\\\n",
    "        .filter(col('SOG') < 58)\\\n",
    "        .filter(col('ship_type') != 'Undefined')\\\n",
    "        .filter(col('ship_type') != 'Law enforcement')\\\n",
    "        .filter(col('type_of_mobile') != 'SAR airborne')\\\n",
    "        .filter(col('MMSI') != 111219507)\n",
    "    \n",
    "    df = df.filter(\n",
    "        (\n",
    "            (col('type_of_mobile') == 'Class A') & (length(col('MMSI')) == 9)\n",
    "        ) | (\n",
    "            (col('type_of_mobile') == 'Class B') & (length(col('MMSI')) == 9)\n",
    "        ) | (\n",
    "            (col('type_of_mobile') == 'Base Station') & (length(col('MMSI')) == 7)\n",
    "        )\n",
    "    ).filter(\n",
    "        (length(col('IMO')) <= 7) | col('IMO').isNull()\n",
    "    )\n",
    "\n",
    "    reduced_df = df.select(\"timestamp\", \"MMSI\", \"lat\", \"long\", \"IMO\", \"type_of_mobile\")\n",
    "    \n",
    "    latitude_center = 55.225000\n",
    "    longitude_center = 14.245000\n",
    "    radius_km = 25\n",
    "\n",
    "    lat_center_rad = math.radians(latitude_center)\n",
    "    long_center_rad = math.radians(longitude_center)\n",
    "\n",
    "    filtered_df = reduced_df.withColumn(\n",
    "    \"distance_km\",\n",
    "    acos(\n",
    "        sin(radians(col(\"lat\"))) * sin(lit(lat_center_rad)) +\n",
    "        cos(radians(col(\"lat\"))) * cos(lit(lat_center_rad)) *\n",
    "        cos(lit(long_center_rad) - radians(col(\"long\")))\n",
    "    ) * 6371  # Earth's radius in km\n",
    "    ).filter(col(\"distance_km\") <= radius_km)\n",
    "\n",
    "    filtered_df = filtered_df.drop(\"distance_km\")\n",
    "\n",
    "    filtered_df = filtered_df.dropDuplicates(['timestamp', 'MMSI'])\n",
    "\n",
    "    output_path = f\"C:/Users/User/Desktop/data_folder/manipulated_data/{file_name.replace('.csv', '')}_processed\"\n",
    "    filtered_df.write.csv(output_path, mode=\"overwrite\", header=True)\n",
    "\n",
    "    print(f\"Processed and saved data for {file_name}  | rows count = {filtered_df.count()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from itertools import combinations\n",
    "from pathlib import Path\n",
    "from haversine import haversine  \n",
    "import logging\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Constants\n",
    "BASE_DIRECTORY = Path(\"C:/Users/User/Desktop/data_folder/manipulated_data/\")\n",
    "WINDOW_SIZE_MINUTES = 20  # 20 minutes window\n",
    "MIN_REPORTS_PER_MINUTE = 1  # Minimum required frequency of reports\n",
    "\n",
    "def generate_directories(base_directory, year, month):\n",
    "    \"\"\"Generate directory names for each day of a given month.\"\"\"\n",
    "    days_in_month = (Path(f\"{base_directory}/aisdk-{year}-{month:02d}-{day:02d}_processed\") \n",
    "                     for day in range(1, 32))\n",
    "    return [d for d in days_in_month if d.exists()]\n",
    "\n",
    "def read_and_process_csvs(directory):\n",
    "    \"\"\"Read and process CSV files in the given directory.\"\"\"\n",
    "    csv_files = glob.glob(str(directory / \"*.csv\"))\n",
    "    \n",
    "    if not csv_files:\n",
    "        logging.warning(f\"No CSV files found in {directory}\")\n",
    "        return None\n",
    "    \n",
    "    df = pd.concat((pd.read_csv(f, usecols=['timestamp', 'MMSI', 'lat', 'long']) for f in csv_files), ignore_index=True)\n",
    "    \n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df.set_index('timestamp', inplace=True)\n",
    "    df.sort_index(inplace=True)\n",
    "    \n",
    "    numeric_cols = df.select_dtypes(include=[np.number])\n",
    "    resampled = numeric_cols.groupby('MMSI').resample('1T').mean()\n",
    "\n",
    "    resampled.dropna(inplace=True)\n",
    "    \n",
    "    if 'MMSI' in resampled.columns:\n",
    "            resampled.drop(columns=['MMSI'], inplace=True)\n",
    "\n",
    "    resampled.reset_index(inplace=True)\n",
    "    return resampled\n",
    "\n",
    "def filter_by_reporting_frequency(df, window_size_minutes, min_reports_per_minute):\n",
    "    \"\"\"Filter out data for vessels that report less frequently than the minimum required frequency within each 20-minute window.\"\"\"\n",
    "    window_size_seconds = window_size_minutes * 60\n",
    "    min_reports_in_window = window_size_minutes * min_reports_per_minute\n",
    "\n",
    "    filtered_df = pd.DataFrame()\n",
    "\n",
    "    for mmsi, group in df.groupby('MMSI'):\n",
    "        group = group.sort_values('timestamp')\n",
    "\n",
    "        group['count_in_window'] = group.rolling(f'{window_size_seconds}S', on='timestamp')['timestamp'].count()\n",
    "\n",
    "        consistent_group = group[group['count_in_window'] >= min_reports_in_window]\n",
    "\n",
    "        filtered_df = pd.concat([filtered_df, consistent_group])\n",
    "\n",
    "    filtered_df = filtered_df.drop(columns=['count_in_window'])\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "def find_closest_vessels(resampled):\n",
    "    \"\"\"Find the closest pair of vessels at each timestamp.\"\"\"\n",
    "    min_distance = float('inf')\n",
    "    closest_pair = None\n",
    "    closest_time = None\n",
    "    collision_coords = None  \n",
    "    \n",
    "    unique_times = resampled['timestamp'].unique()\n",
    "    \n",
    "    for time in unique_times:\n",
    "        subframe = resampled[resampled['timestamp'] == time]\n",
    "        for (idx1, row1), (idx2, row2) in combinations(subframe.iterrows(), 2):\n",
    "            dist = haversine((row1['lat'], row1['long']), (row2['lat'], row2['long']))\n",
    "            if dist < min_distance:\n",
    "                min_distance = dist\n",
    "                closest_pair = (row1['MMSI'], row2['MMSI'])\n",
    "                closest_time = time\n",
    "                collision_coords = (\n",
    "                    (row1['lat'], row1['long']),\n",
    "                    (row2['lat'], row2['long'])\n",
    "                )\n",
    "\n",
    "    return min_distance, closest_pair, closest_time, collision_coords\n",
    "\n",
    "def process_directory(directory):\n",
    "    \"\"\"Process each directory to find the closest vessels.\"\"\"\n",
    "    resampled_data = read_and_process_csvs(directory)\n",
    "    \n",
    "    if resampled_data is not None:\n",
    "        consistent_data = filter_by_reporting_frequency(resampled_data, WINDOW_SIZE_MINUTES, MIN_REPORTS_PER_MINUTE)\n",
    "        \n",
    "        if consistent_data.empty:\n",
    "            logging.info(f\"No consistent data found for directory: {directory}\")\n",
    "            return None\n",
    "        \n",
    "        min_distance, closest_pair, closest_time, collision_coords = find_closest_vessels(consistent_data)\n",
    "        \n",
    "        if min_distance < float('inf'):\n",
    "            print(f\"Closest vessels were {closest_pair} with a distance of {min_distance:.3f} km at {collision_coords} at {closest_time}\")\n",
    "            return min_distance, closest_pair, closest_time, collision_coords\n",
    "        else:\n",
    "            logging.info(f\"No close encounters found for directory: {directory}\")\n",
    "            return None\n",
    "    else:\n",
    "        logging.info(f\"No data processed for directory: {directory}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "year = 2021\n",
    "month = 12\n",
    "\n",
    "overall_min_distance = float('inf')\n",
    "overall_closest_pair = None\n",
    "overall_closest_time = None\n",
    "overall_day = None\n",
    "\n",
    "directories = generate_directories(BASE_DIRECTORY, year, month)\n",
    "\n",
    "for directory in directories:\n",
    "    logging.info(f\"Processing directory: {directory}\")\n",
    "    \n",
    "    result = process_directory(directory)\n",
    "    if result is not None:\n",
    "        min_distance, closest_pair, closest_time, collision_coords = result\n",
    "        if min_distance < overall_min_distance:\n",
    "            overall_min_distance = min_distance\n",
    "            overall_closest_pair = closest_pair\n",
    "            overall_closest_time = closest_time\n",
    "            overall_day = directory.name\n",
    "\n",
    "print('------------------------------------------------------------------------------------------------------------------------------------------')\n",
    "print(f\"During the whole month closest vessels were {overall_closest_pair} with a distance of {overall_min_distance:.3f} km at {collision_coords} at {overall_closest_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "window_size_minutes = 20  # 20 minutes window\n",
    "min_reports_per_minute = 1  # Minimum required frequency of reports\n",
    "\n",
    "window_size_seconds = window_size_minutes * 60\n",
    "min_reports_in_window = window_size_minutes * min_reports_per_minute\n",
    "\n",
    "collision_time_str = \"2021-12-13 06:18:00+02:00\"\n",
    "collision_time = pd.to_datetime(collision_time_str)\n",
    "\n",
    "start_time = collision_time - timedelta(minutes=400)\n",
    "end_time = collision_time\n",
    "\n",
    "path = 'C:/Users/User/Desktop/data_folder/manipulated_data/aisdk-2021-12-13_processed'\n",
    "all_files = glob.glob(path + \"/part*.csv\")\n",
    "mmsi_list = [219001468, 219019015]\n",
    "\n",
    "\n",
    "df = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "    \n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df = df[df['MMSI'].isin(mmsi_list)]\n",
    "df.set_index('timestamp', inplace=True)\n",
    "df.sort_index(inplace=True)\n",
    "\n",
    "numeric_cols = df.select_dtypes(include=[np.number])\n",
    "resampled = numeric_cols.groupby('MMSI').resample('1T').mean()\n",
    "resampled.dropna(inplace=True)\n",
    "\n",
    "if 'MMSI' in resampled.columns:\n",
    "        resampled.drop(columns=['MMSI'], inplace=True)\n",
    "\n",
    "resampled.reset_index(inplace=True)\n",
    "\n",
    "filtered_df = pd.DataFrame()\n",
    "\n",
    "for mmsi, group in resampled.groupby('MMSI'):\n",
    "    group = group.sort_values('timestamp')\n",
    "    group['count_in_window'] = group.rolling(f'{window_size_seconds}S', on='timestamp')['timestamp'].count()\n",
    "    consistent_group = group[group['count_in_window'] >= min_reports_in_window]\n",
    "    filtered_df = pd.concat([filtered_df, consistent_group])\n",
    "    filtered_df = filtered_df.drop(columns=['count_in_window'])\n",
    "\n",
    "filtered_df = resampled[(resampled['timestamp'] >= start_time) & (resampled['timestamp'] <= end_time)]\n",
    "\n",
    "for mmsi in mmsi_list:\n",
    "    mmsi_df = filtered_df[filtered_df['MMSI'] == mmsi].sort_values(by='timestamp')\n",
    "    plt.plot(mmsi_df['long'], mmsi_df['lat'], marker='o', label=f'MMSI {mmsi}')\n",
    "\n",
    "plt.title('Ship Trajectories 20 Minutes Before Closest point')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
